{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"bond_issue_log.csv\")\n",
    "\n",
    "df['severity'] = df['severity'].replace({'tiny': 1, 'low': 2, 'normal': 3, 'high': 4, 'critical': 5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module\n",
      "Core        0.785377\n",
      "Module A    0.803663\n",
      "Module B    0.688554\n",
      "Module C    0.930874\n",
      "Module D    0.624570\n",
      "Module E    0.543377\n",
      "Module F    0.657705\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1.\tWhat is the least reliable component of the system?\n",
    "\n",
    "# Reliability Score = (Bug Frequency * 0.4) + (Severity Index * 0.3) + (Reopened rate * 0.3)\n",
    "\n",
    "# Bug frequency per module = the total number of bugs reported\n",
    "# Severity Index per module = the average severity of the bugs reported \n",
    "# Reopned Rate per module = divide the number of reopened bugs by the total number of bugs\n",
    "\n",
    "def calc_reliability_score(df):  \n",
    "    \"\"\"\n",
    "    Calculate reliability score for module\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Bug Counts Trend per sprint\n",
    "    frequency_index= df.groupby('module')['title'].count()\n",
    "\n",
    "    # Calculate Severity Index Trend per sprint\n",
    "    severity_index = df.groupby('module')['severity'].mean()\n",
    "\n",
    "    # Calculate Reopened Rate Trend per sprint\n",
    "    reopened_index = df.groupby('module')['reopened #'].mean()\n",
    "\n",
    "    # Normalize the values\n",
    "    frequency_index = frequency_index / frequency_index.max()\n",
    "    severity_index = severity_index / severity_index.max()\n",
    "    reopened_index = reopened_index / reopened_index.max()\n",
    "\n",
    "    # Calculate Quality Trend Score as per given formula\n",
    "    module_reliability_score = (frequency_index * 0.4) + (severity_index * 0.3) + (reopened_index * 0.3)\n",
    "\n",
    "    return module_reliability_score\n",
    "\n",
    "\n",
    "modules_scores = calc_reliability_score(df)\n",
    "modules_scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sprint / week #\n",
       "12    0.796319\n",
       "13    0.805782\n",
       "14    0.877506\n",
       "15    0.718109\n",
       "16    0.890319\n",
       "17    0.875314\n",
       "18    0.792239\n",
       "19    0.879391\n",
       "20    0.810436\n",
       "21    0.831408\n",
       "22    0.883529\n",
       "23    0.860205\n",
       "24    0.925689\n",
       "25    0.782092\n",
       "26    0.828935\n",
       "27    0.660564\n",
       "28    0.749139\n",
       "29    0.691371\n",
       "30    0.737104\n",
       "31    0.532043\n",
       "32    0.750979\n",
       "33    0.709427\n",
       "34    0.742228\n",
       "35    0.707636\n",
       "36    0.782004\n",
       "37    0.688201\n",
       "38    0.822475\n",
       "39    0.670494\n",
       "40    0.639713\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_quality_trend_score(df):\n",
    "    \"\"\"\n",
    "    Calculate Quality Trend Score of sprints based on bug_count_trend, severity_index_trend, reopened_rate_trend.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate Bug Counts Trend per sprint\n",
    "    bug_count_trend = df.groupby('sprint / week #')['title'].count()\n",
    "\n",
    "    # Calculate Severity Index Trend per sprint\n",
    "    severity_index_trend = df.groupby('sprint / week #')['severity'].mean()\n",
    "\n",
    "    # Calculate Reopened Rate Trend per sprint\n",
    "    reopened_rate_trend = df.groupby('sprint / week #')['reopened #'].mean()\n",
    "\n",
    "    # Normalize the values\n",
    "    bug_count_trend = bug_count_trend / bug_count_trend.max()\n",
    "    severity_index_trend = severity_index_trend / severity_index_trend.max()\n",
    "    reopened_rate_trend = reopened_rate_trend / reopened_rate_trend.max()\n",
    "\n",
    "    # Calculate Quality Trend Score as per given formula\n",
    "    quality_trend_score = (bug_count_trend * 0.4) + (severity_index_trend * 0.3) + (reopened_rate_trend * 0.3)\n",
    "\n",
    "    return quality_trend_score\n",
    "\n",
    "\n",
    "# Call the function\n",
    "quality_trend_scores = calc_quality_trend_score(df)\n",
    "\n",
    "# Displaying results\n",
    "quality_trend_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sprint / week #\n",
       " 16    40\n",
       " 17    38\n",
       " 14    37\n",
       " 19    36\n",
       " 23    36\n",
       " 24    36\n",
       " 13    36\n",
       " 15    33\n",
       " 20    31\n",
       " 22    31\n",
       " 21    29\n",
       " 25    29\n",
       " 12    28\n",
       " 18    28\n",
       " 28    27\n",
       " 26    27\n",
       " 27    26\n",
       " 29    19\n",
       " 37    12\n",
       " 38     8\n",
       " 36     7\n",
       " 34     6\n",
       " 33     5\n",
       " 30     4\n",
       " 32     3\n",
       " 35     3\n",
       " 40     3\n",
       " 39     2\n",
       " dtype: int64,\n",
       " sprint / week #\n",
       " 22    16\n",
       " 40    14\n",
       " 38    13\n",
       " 39    11\n",
       " 24    11\n",
       " 18    10\n",
       " 23     9\n",
       " 16     9\n",
       " 35     9\n",
       " 34     8\n",
       " 32     8\n",
       " 12     8\n",
       " 26     8\n",
       " 17     8\n",
       " 30     7\n",
       " 37     7\n",
       " 19     7\n",
       " 21     7\n",
       " 25     6\n",
       " 13     6\n",
       " 29     5\n",
       " 27     5\n",
       " 31     4\n",
       " 28     4\n",
       " 36     4\n",
       " 20     4\n",
       " 33     3\n",
       " 15     2\n",
       " 14     1\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.\tWhat weeks were the most dynamic in testing/development?\n",
    "\n",
    "# Bugs Found: Count the number of bugs identified each week. A high number of reported bugs could indicate a week of intensive testing.\n",
    "\n",
    "# Bugs Resolved: Count the number of bugs resolved each week. A high number of resolved bugs could point to the productive and dynamic development period.\n",
    "\n",
    "def count_bugs_dynamic(df):\n",
    "    \"\"\"\n",
    "    Counts the number of bugs found and resolved in each sprint / week. orders descending\n",
    "    \"\"\"\n",
    "    # Calculate bugs found in each sprint / week\n",
    "    bugs_found = df[df['status'].isin(['verified', 'opened'])].groupby('sprint / week #').size().sort_values(ascending=False)\n",
    "\n",
    "    # Calculate bugs resolved in each sprint / week\n",
    "    bugs_resolved = df[df['status'] == 'fixed'].groupby('sprint / week #').size().sort_values(ascending=False)\n",
    "\n",
    "    return bugs_found, bugs_resolved\n",
    "\n",
    "\n",
    "# Call the function\n",
    "dynamic_trend = count_bugs_dynamic(df)\n",
    "\n",
    "# Displaying results\n",
    "dynamic_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sprint / week #\n",
       " 39     2\n",
       " 40     3\n",
       " 35     3\n",
       " 32     3\n",
       " 30     4\n",
       " 33     5\n",
       " 34     6\n",
       " 36     7\n",
       " 38     8\n",
       " 37    12\n",
       " 29    19\n",
       " 27    26\n",
       " 28    27\n",
       " 26    27\n",
       " 12    28\n",
       " 18    28\n",
       " 21    29\n",
       " 25    29\n",
       " 22    31\n",
       " 20    31\n",
       " 15    33\n",
       " 23    36\n",
       " 19    36\n",
       " 13    36\n",
       " 24    36\n",
       " 14    37\n",
       " 17    38\n",
       " 16    40\n",
       " dtype: int64,\n",
       " sprint / week #\n",
       " 14     1\n",
       " 15     2\n",
       " 33     3\n",
       " 20     4\n",
       " 31     4\n",
       " 36     4\n",
       " 28     4\n",
       " 27     5\n",
       " 29     5\n",
       " 25     6\n",
       " 13     6\n",
       " 21     7\n",
       " 37     7\n",
       " 30     7\n",
       " 19     7\n",
       " 34     8\n",
       " 32     8\n",
       " 12     8\n",
       " 26     8\n",
       " 17     8\n",
       " 23     9\n",
       " 35     9\n",
       " 16     9\n",
       " 18    10\n",
       " 24    11\n",
       " 39    11\n",
       " 38    13\n",
       " 40    14\n",
       " 22    16\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.\tWhat weeks were the most silent?\n",
    "# Bugs Found: Weeks with a lower number of discovered bugs could indicate quieter testing periods.\n",
    "\n",
    "# Bugs Resolved: Weeks with a less number of resolved bugs could point towards a less active development period.\n",
    "\n",
    "def count_bugs_silent(df):\n",
    "    \"\"\"\n",
    "    Counts the number of bugs found and resolved in each sprint / week. orders ascending\n",
    "    \"\"\"\n",
    "    # Calculate bugs found in each sprint / week\n",
    "    bugs_found = df[df['status'].isin(['verified', 'opened'])].groupby('sprint / week #').size().sort_values(ascending=True)\n",
    "\n",
    "    # Calculate bugs resolved in each sprint / week\n",
    "    bugs_resolved = df[df['status'] == 'fixed'].groupby('sprint / week #').size().sort_values(ascending=True)\n",
    "\n",
    "    return bugs_found, bugs_resolved\n",
    "\n",
    "\n",
    "# Call the function\n",
    "silent_trend = count_bugs_silent(df)\n",
    "\n",
    "# Displaying results\n",
    "silent_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sprint / week #\n",
       "12     True\n",
       "13     True\n",
       "14     True\n",
       "15    False\n",
       "16     True\n",
       "17     True\n",
       "18     True\n",
       "19     True\n",
       "20     True\n",
       "21     True\n",
       "22     True\n",
       "23     True\n",
       "24     True\n",
       "25     True\n",
       "26     True\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "30    False\n",
       "31    False\n",
       "32    False\n",
       "33    False\n",
       "34    False\n",
       "35    False\n",
       "36    False\n",
       "37    False\n",
       "38     True\n",
       "39     True\n",
       "40     True\n",
       "Name: severity, dtype: bool"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.\tSuggest a threshold for bug quantity per week (take into consideration their severity)\n",
    "\n",
    "# To calculate a threshold, we could assign points to bugs based on their severity level. \n",
    "# For example I would suggest to set threshold to 200 points, this could be reached with ten tiny-severity bugs, or mix of severity of bugs.\n",
    "\n",
    "\n",
    "def check_threshold(df, threshold):\n",
    "    \"\"\"\n",
    "    Check if the total severity points exceed the threshold in each sprint / week.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate total severity points for each sprint / week\n",
    "    total_severity_points = df.groupby('sprint / week #')['severity'].sum()\n",
    "\n",
    "    # Check if total severity points exceed the threshold\n",
    "    exceeds_threshold = total_severity_points > threshold\n",
    "\n",
    "    return exceeds_threshold\n",
    "\n",
    "\n",
    "threshold_check = check_threshold(df, 200)\n",
    "\n",
    "threshold_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
